# ğŸ¦ Credit Fraud Detection â€” Machine Learning

### PrevisÃ£o de transaÃ§Ãµes bancÃ¡rias fraudulentas usando aprendizado de mÃ¡quina

Este projeto implementa um pipeline completo para **detecÃ§Ã£o de fraudes em cartÃµes de crÃ©dito**, utilizando o dataset real *Credit Card Fraud Detection* do Kaggle.
O objetivo Ã© construir um sistema escalÃ¡vel, interpretÃ¡vel e aplicÃ¡vel a cenÃ¡rios reais do setor bancÃ¡rio.

---

## ğŸ“Š Dataset

**Fonte:** Kaggle â€” *Credit Card Fraud Detection*
**Link:** [https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)

### **CaracterÃ­sticas principais:**

* 284.807 transaÃ§Ãµes
* Apenas **0,17%** sÃ£o fraudes (extremamente desbalanceado)
* Features V1â€“V28 sÃ£o componentes PCA (dados anonimizados)
* Coluna **Class** Ã© o alvo:

  * `0` â†’ legÃ­tima
  * `1` â†’ fraude

---

## ğŸ” Exploratory Data Analysis (EDA)

### âœ” DistribuiÃ§Ã£o das classes

* Fraudes < 1% â†’ necessidade de tÃ©cnicas de balanceamento (SMOTE).

### âœ” AnÃ¡lise das Features

* Features PCA apresentam padrÃµes distintos entre fraudes e nÃ£o fraudes.
* `Amount` apresenta alta variabilidade e cauda longa.

### âœ” CorrelaÃ§Ã£o

* V17, V14 e V12 correlacionam fortemente com a classe.
* PCA preserva componentes discriminativas importantes.

### âœ” Outliers

* Mantidos (esperados apÃ³s PCA).

### âœ” GrÃ¡ficos utilizados

* Histogramas
* Countplot
* Heatmap de correlaÃ§Ã£o
* Boxplots

---

## ğŸ§¹ PrÃ©-processamento

Pipeline implementado em **`src/preprocessing.py`**.

### âœ” 1. SeparaÃ§Ã£o X / y

### âœ” 2. Train-test split (80/20, estratificado)

### âœ” 3. NormalizaÃ§Ã£o (StandardScaler)

Scaler salvo em:

```
models/scaler.pkl
```

### âœ” 4. Balanceamento com SMOTE

### âœ” 5. Salvamento dos arrays processados

Arquivos gerados:

```
data/processed/
  â”œâ”€â”€ X_train_bal.npy
  â”œâ”€â”€ X_test.npy
  â”œâ”€â”€ y_train_bal.npy
  â”œâ”€â”€ y_test.npy
```

### âœ” 6. Pipeline final

Carrega dados â†’ separa â†’ divide â†’ escala â†’ balanceia â†’ salva â†’ retorna shapes.

---

# ğŸ¤– Modelagem

Foram treinados **5 modelos**:

* Logistic Regression
* Random Forest
* Gradient Boosting
* XGBoost
* LightGBM

Todos treinados em `train_model.py`.

---

# ğŸ“Œ 1. Logistic Regression

### ğŸ“Š Resultados

* **ROC-AUC:** 0.9709
* **Recall:** 0.9183
* **Precision:** 0.0579

### ğŸ§© Matriz de ConfusÃ£o

|            | Prev. 0 | Prev. 1 |
| ---------- | ------- | ------- |
| **Real 0** | 55402   | 1462    |
| **Real 1** | 8       | 90      |

### âœ” InterpretaÃ§Ã£o

* Ã“tima separaÃ§Ã£o (AUC 0.97)
* Excelente recall
* Baixa precisÃ£o, esperado no desbalanceamento

---

# ğŸ“Œ 2. Random Forest

### ğŸ“Š Resultados

* **ROC-AUC:** 0.9684
* **Recall:** 0.8265
* **Precision:** 0.8709

### ğŸ§© Matriz de ConfusÃ£o

|            | Prev. 0 | Prev. 1 |
| ---------- | ------- | ------- |
| **Real 0** | 56852   | 12      |
| **Real 1** | 17      | 81      |

### âœ” InterpretaÃ§Ã£o

* AltÃ­ssima precisÃ£o
* Recall mais baixo
* Ideal quando se quer evitar falsos positivos

---

# ğŸ“Œ 3. Gradient Boosting

### ğŸ“Š Resultados

* **ROC-AUC:** 0.9809
* **Recall:** 0.9183
* **Precision:** 0.1133

### ğŸ§© Matriz de ConfusÃ£o

|            | Prev. 0 | Prev. 1 |
| ---------- | ------- | ------- |
| **Real 0** | 56160   | 704     |
| **Real 1** | 8       | 90      |

### âœ” InterpretaÃ§Ã£o

* Melhor AUC entre os modelos
* Recall excelente
* PrecisÃ£o baixa devido ao desbalanceamento

---

# ğŸ“Œ 4. XGBoost

### ğŸ“Š Resultados

* **ROC-AUC:** 0.9800
* **Recall:** 0.8775
* **Precision:** 0.2409

### ğŸ§© Matriz de ConfusÃ£o

|            | Prev. 0 | Prev. 1 |
| ---------- | ------- | ------- |
| **Real 0** | 56593   | 271     |
| **Real 1** | 12      | 86      |

### âœ” InterpretaÃ§Ã£o

* Excelente AUC
* Bom recall
* Melhor precisÃ£o que LR/GB

---

# ğŸ“Œ 5. LightGBM

### ğŸ“Š Resultados

* **ROC-AUC:** 0.9568
* **Recall:** 0.8367
* **Precision:** 0.6259

### ğŸ§© Matriz de ConfusÃ£o

|            | Prev. 0 | Prev. 1 |
| ---------- | ------- | ------- |
| **Real 0** | 56815   | 49      |
| **Real 1** | 16      | 82      |

### âœ” InterpretaÃ§Ã£o

* Excelente precisÃ£o
* Bom recall
* Menor AUC que XGBoost/GB

---

# ğŸ† ComparaÃ§Ã£o Geral dos Modelos

| Modelo              | ROC-AUC | Recall | Precision |
| ------------------- | ------- | ------ | --------- |
| Logistic Regression | 0.9709  | 0.9183 | 0.0579    |
| Random Forest       | 0.9684  | 0.8265 | 0.8709    |
| Gradient Boosting   | 0.9809  | 0.9183 | 0.1133    |
| XGBoost             | 0.9800  | 0.8775 | 0.2409    |
| LightGBM            | 0.9568  | 0.8367 | 0.6259    |

### âœ” ConclusÃµes Profissionais

* **Melhor AUC:** Gradient Boosting
* **Melhor Recall:** Logistic Regression & Gradient Boosting
* **Melhor Precision:** Random Forest (de longe)

Cada modelo apresenta vantagens especÃ­ficas â†’ perfeito para testes de ensemble no futuro.

---

# ğŸ”® PrÃ³ximas Etapas

### ğŸ”§ Machine Learning AvanÃ§ado

* HiperparametrizaÃ§Ã£o (Grid Search / Optuna)
* Ensemble (VotaÃ§Ã£o, Stacking)

### ğŸ¤– Deep Learning

* MLP
* Early Stopping

### ğŸ— Infraestrutura

* Pipeline de produÃ§Ã£o
* FastAPI para servir o modelo
* Script de inferÃªncia

---

## âš™ Tecnologias Utilizadas

* Python 3.10+
* Pandas / NumPy
* Matplotlib / Seaborn
* Scikit-learn
* Imbalanced-Learn
* XGBoost
* LightGBM
* TensorFlow
* Joblib
* Jupyter Notebook

---

## ğŸ“Œ Status Atual

### âœ” ConcluÃ­do

* EDA completo
* Pipeline de prÃ©-processamento
* SMOTE
* Treinamento de **5 modelos**
* ComparaÃ§Ã£o completa

### â¡ PrÃ³xima Etapa

* Tuning + API
* Escolha do modelo final para produÃ§Ã£o

---
