# ğŸ¦ Credit Fraud Detection â€” Machine Learning

### PrevisÃ£o de transaÃ§Ãµes bancÃ¡rias fraudulentas usando aprendizado de mÃ¡quina

Este projeto constrÃ³i um pipeline completo para **detectar fraudes em cartÃµes de crÃ©dito**, utilizando o dataset real â€œCredit Card Fraud Detectionâ€ do Kaggle.
O foco Ã© desenvolver um modelo robusto, escalÃ¡vel e aplicÃ¡vel a cenÃ¡rios reais de anÃ¡lise bancÃ¡ria.

---

## ğŸ“Š Dataset

**Fonte:** Kaggle â€” *Credit Card Fraud Detection*
Link: [https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
**ObservaÃ§Ãµes principais:**

* 284.807 transaÃ§Ãµes
* Apenas **0.17%** sÃ£o fraudulentas â†’ *problema severo de desbalanceamento*
* VariÃ¡veis V1â€“V28 foram reduzidas por PCA (dados anonimizados)
* A coluna **Class** Ã© a variÃ¡vel-alvo

  * `0` â†’ transaÃ§Ã£o normal
  * `1` â†’ fraude

---

## ğŸ” Exploratory Data Analysis (EDA)

Principais anÃ¡lises realizadas:

### âœ”ï¸ DistribuiÃ§Ãµes

* Fraude representa menos de 1% â†’ extremamente desbalanceado.
* Features PCA (V1â€“V28) apresentam distribuiÃ§Ã£o centrada e comportamento diferente entre fraudes e nÃ£o fraudes.

### âœ”ï¸ CorrelaÃ§Ã£o

* Forte correlaÃ§Ã£o negativa entre **V17, V14, V12** e a classe (fraude).
* Isso indica que algumas componentes PCA carregam sinal importante.

### âœ”ï¸ Outliers

* Algumas variÃ¡veis possuem valores extremos, mas fazem sentido para dados PCA e nÃ£o foram removidos.

### âœ”ï¸ GrÃ¡ficos utilizados

* Histogramas por classe
* Heatmap de correlaÃ§Ã£o
* Countplot de fraudes
* Boxplots comparativos

---

## ğŸ§¹ PrÃ©-processamento

### Passos implementados:

### âœ”ï¸ 1. SeparaÃ§Ã£o X / y

* `Class` Ã© a coluna alvo
* Todas as demais variÃ¡veis â†’ features

### âœ”ï¸ 2. Train-test split

* ProporÃ§Ã£o 80/20
* Estratificado (mantÃ©m proporÃ§Ã£o de fraudes)

### âœ”ï¸ 3. NormalizaÃ§Ã£o (StandardScaler)

* Aplicado **apenas no treino**
* TransformaÃ§Ã£o posteriormente aplicada ao teste

### âœ”ï¸ 4. Balanceamento SMOTE

O SMOTE (*Synthetic Minority Oversampling Technique*) gera novos exemplos sintÃ©ticos da classe minoritÃ¡ria.
Aplicamos **somente no conjunto de treino**, evitando vazamento de informaÃ§Ã£o.

### âœ”ï¸ 5. Salvamento dos arquivos processados

Todos os arrays sÃ£o salvos em:

```
data/processed/
  â”œâ”€â”€ X_train_bal.npy
  â”œâ”€â”€ X_test.npy
  â”œâ”€â”€ y_train_bal.npy
  â”œâ”€â”€ y_test.npy
```

### âœ”ï¸ 6. Pipeline completo implementado

FunÃ§Ã£o: **preprocess_pipeline()**

Ela executa:

1. Carregar dados
2. Separar X/y
3. Dividir treino/teste
4. Escalar
5. Balancear
6. Salvar arrays
7. Retornar formas (debug)

---

## ğŸ¤– Modelos (prÃ³ximas etapas)

SerÃ£o implementados:

### Machine Learning

* Logistic Regression
* Random Forest
* Gradient Boosting
* XGBoost / LightGBM

### MÃ©tricas

* ROC-AUC
* Recall (prioridade)
* Precision
* Confusion Matrix

### Deep Learning (MLP)

* Rede neural densa
* Early stopping
* ComparaÃ§Ã£o final com modelos clÃ¡ssicos

---

## âš™ï¸ Tecnologias Utilizadas

* Python 3.10+
* Pandas / NumPy
* Matplotlib / Seaborn
* Scikit-learn
* Imbalanced-Learn (SMOTE)
* TensorFlow (CPU)
* Jupyter Notebook

---

## ğŸ“Œ Status

**Etapa atual:** PrÃ©-processamento completo finalizado
**PrÃ³xima etapa:** Treinamento dos modelos de Machine Learning

---

Se quiser, posso gerar uma **versÃ£o ainda mais profissional** com badges e tabela de mÃ©tricas.
Quer que eu evolua o README nesse estilo?
