# ğŸ¦ Credit Fraud Detection â€” Machine Learning

### PrevisÃ£o de transaÃ§Ãµes bancÃ¡rias fraudulentas usando aprendizado de mÃ¡quina

Este projeto implementa um pipeline completo para **detecÃ§Ã£o de fraudes em cartÃµes de crÃ©dito**, utilizando o dataset real *Credit Card Fraud Detection* do Kaggle.
O foco Ã© construir um sistema escalÃ¡vel, interpretÃ¡vel e aplicÃ¡vel a cenÃ¡rios reais do setor bancÃ¡rio.

---

## ğŸ“Š Dataset

**Fonte:** Kaggle â€” *Credit Card Fraud Detection*
**Link:** [https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)

### **CaracterÃ­sticas principais:**

* 284.807 transaÃ§Ãµes
* Apenas **0,17%** sÃ£o fraudulentas â†’ *problema severamente desbalanceado*
* Features V1â€“V28 geradas por PCA (dados anonimizados)
* Coluna **Class** Ã© a variÃ¡vel-alvo:

  * `0` â†’ transaÃ§Ã£o normal
  * `1` â†’ transaÃ§Ã£o fraudulenta

---

## ğŸ” Exploratory Data Analysis (EDA)

### âœ” DistribuiÃ§Ã£o das classes

* Fraude representa menos de 1% das transaÃ§Ãµes.
* Indica necessidade de reamostragem (SMOTE).

### âœ” AnÃ¡lise das features

* VariÃ¡veis PCA (V1â€“V28) possuem padrÃµes diferentes entre fraudes e nÃ£o fraudes.
* VariÃ¡vel `Amount` apresenta cauda longa e alta variabilidade.

### âœ” CorrelaÃ§Ã£o

* Componentes **V17, V14 e V12** mostram forte relaÃ§Ã£o com a classe fraudulenta.
* Algumas componentes PCA carregam alto poder discriminativo.

### âœ” Outliers

* Presentes, mas esperados em dados transformados por PCA.
* Mantidos no conjunto.

### âœ” GrÃ¡ficos utilizados

* Histogramas por classe
* Heatmap de correlaÃ§Ã£o
* Countplot das classes
* Boxplots de variÃ¡veis importantes

---

## ğŸ§¹ PrÃ©-processamento

O prÃ©-processamento foi implementado em `src/preprocessing.py` dentro de um pipeline automatizado.

### âœ” 1. SeparaÃ§Ã£o X / y

* `Class` Ã© a variÃ¡vel-alvo.
* Demais colunas sÃ£o features.

### âœ” 2. Train-test split (80/20)

* DivisÃ£o estratificada para preservar proporÃ§Ã£o de fraudes.

### âœ” 3. NormalizaÃ§Ã£o (StandardScaler)

* Ajustado **somente no conjunto de treino**.
* Aplicado no teste para evitar *data leakage*.
* Scaler salvo em:

```
models/scaler.pkl
```

### âœ” 4. Balanceamento com SMOTE

* Aplicado apenas no treino.
* Aumenta a classe minoritÃ¡ria de forma sintÃ©tica.
* Melhora o aprendizado em datasets desbalanceados.

### âœ” 5. Salvamento dos dados processados

Arquivos gerados:

```
data/processed/
  â”œâ”€â”€ X_train_bal.npy
  â”œâ”€â”€ X_test.npy
  â”œâ”€â”€ y_train_bal.npy
  â”œâ”€â”€ y_test.npy
```

### âœ” 6. Pipeline completo (`preprocess_pipeline()`)

Fluxo implementado:

1. Carrega os dados
2. Separa features e target
3. Divide treino/teste
4. Escala os dados
5. Aplica SMOTE
6. Salva scaler + arrays
7. Retorna formas para validaÃ§Ã£o

---

## ğŸ¤– Modelagem â€” Logistic Regression (Etapa finalizada)

O primeiro modelo treinado foi **RegressÃ£o LogÃ­stica**, utilizando os dados prÃ©-processados.

### ğŸ“Š Resultados Obtidos

**ROC-AUC:** 0.9709
**Recall:** 0.9183
**Precision:** 0.0579

### ğŸ“Œ Matriz de ConfusÃ£o

|            | Previsto 0 | Previsto 1 |
| ---------- | ---------- | ---------- |
| **Real 0** | 55402      | 1462       |
| **Real 1** | 8          | 90         |

### ğŸ“ InterpretaÃ§Ã£o profissional

* **ROC-AUC de 0.97** â†’ excelente capacidade de separaÃ§Ã£o.
* **Recall = 91,8%** â†’ modelo recupera a maioria das fraudes (prioridade do setor).
* **PrecisÃ£o baixa (5,7%)** â†’ esperado em datasets extremamente desbalanceados.
* **Apenas 8 fraudes nÃ£o detectadas** â†’ Ã³timo desempenho para aplicaÃ§Ãµes reais.

---

## ğŸ”® PrÃ³ximas Etapas (Dia 5 em diante)

### Machine Learning:

* Random Forest
* Gradient Boosting
* XGBoost / LightGBM

### Deep Learning:

* MLP (rede neural densa)
* Early Stopping
* ComparaÃ§Ã£o com modelos tradicionais

### RelatÃ³rios:

* Tabelas comparativas de mÃ©tricas
* GrÃ¡ficos de performance
* SeleÃ§Ã£o de modelo final para produÃ§Ã£o

---

## âš™ Tecnologias Utilizadas

* Python 3.10+
* Pandas / NumPy
* Matplotlib / Seaborn
* Scikit-learn
* Imbalanced-Learn (SMOTE)
* TensorFlow (CPU)
* Joblib
* Jupyter Notebook

---

## ğŸ“Œ Status Atual

**Etapa concluÃ­da:**
âœ” PrÃ©-processamento completo
âœ” Treinamento e avaliaÃ§Ã£o do modelo Logistic Regression

**PrÃ³xima etapa:**
â¡ Treinar modelos avanÃ§ados (Random Forest, Gradient Boosting)

---
