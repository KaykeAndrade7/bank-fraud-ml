# ğŸ¦ Credit Fraud Detection â€” Machine Learning

### PrevisÃ£o de transaÃ§Ãµes bancÃ¡rias fraudulentas usando aprendizado de mÃ¡quina

Este projeto implementa um pipeline completo para **detecÃ§Ã£o de fraudes em cartÃµes de crÃ©dito**, utilizando o dataset real *Credit Card Fraud Detection* do Kaggle.
O objetivo Ã© construir um sistema escalÃ¡vel, interpretÃ¡vel e aplicÃ¡vel a cenÃ¡rios reais do setor bancÃ¡rio â€” passando por EDA, prÃ©-processamento, modelagem, tuning e geraÃ§Ã£o automÃ¡tica de relatÃ³rios.

---

# ğŸ“Š Dataset

**Fonte:** Kaggle â€” *Credit Card Fraud Detection*
Link: [https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)

### **CaracterÃ­sticas principais**

* 284.807 transaÃ§Ãµes
* Apenas **0,17%** sÃ£o fraudes
* Features **V1â€“V28** geradas via PCA
* Alvo:

  * `0` â†’ legÃ­tima
  * `1` â†’ fraudulenta

---

# ğŸ” Exploratory Data Analysis (EDA)

âœ” Fraudes < 1% (dataset extremamente desbalanceado)
âœ” PCA cria componentes informativos â†’ V17, V14, V12 se destacam
âœ” `Amount` com cauda longa
âœ” Outliers mantidos
âœ” GrÃ¡ficos: histogramas, boxplots, countplot, correlaÃ§Ã£o

---

# ğŸ§¹ PrÃ©-processamento

Pipeline em **`src/preprocessing.py`**, contendo:

1. SeparaÃ§Ã£o X / y
2. Train-test split 80/20 estratificado
3. NormalizaÃ§Ã£o (StandardScaler)
4. Balanceamento com SMOTE
5. Salvamento dos arrays processados

Arquivos gerados:

```
data/processed/
  â”œâ”€â”€ X_train_bal.npy
  â”œâ”€â”€ X_test.npy
  â”œâ”€â”€ y_train_bal.npy
  â”œâ”€â”€ y_test.npy
```

Scaler salvo em `models/scaler.pkl`.

---

# ğŸ¤– Modelagem â€” Modelos Base

Foram treinados 5 modelos iniciais:

* Logistic Regression
* Random Forest
* Gradient Boosting
* XGBoost
* LightGBM

Com mÃ©tricas avaliadas em ROC-AUC, Recall, Precision e matriz de confusÃ£o.

(Se desejar manter a seÃ§Ã£o antiga com resultados *antes* do tuning, deixe como estÃ¡.)

---

# âš™ï¸ Tuning de HiperparÃ¢metros (NOVO â€” Dia 8)

Nesta etapa, cada modelo foi **otimizado individualmente** usando `RandomizedSearchCV`, sempre com foco em:

âœ” Maximizar **ROC-AUC**
âœ” Manter execuÃ§Ã£o leve para evitar sobreaquecimento
âœ” Reduzir busca para estabilidade e performance

FunÃ§Ãµes de tuning implementadas em:
**`src/tuning.py`**

Modelos tunados:

### **1. Logistic Regression (Tuned)**

* Ajuste de `C`, `penalty`, `solver`
* Resultado:

  * ROC-AUC: **0.9755**
  * Precision: **0.8235**
  * Recall: **0.5714**

â†’ Modelo mais conservador apÃ³s tuning (alta precisÃ£o, recall menor).

---

### **2. Random Forest (Tuned)**

* Ajuste de nÃºmero de Ã¡rvores, profundidade, min_samples, max_features
* Resultado:

  * ROC-AUC: **0.9652**
  * Recall: **0.7959**
  * Precision: **0.8764**

â†’ Modelo mais equilibrado e robusto.

---

### **3. Gradient Boosting (Tuned)**

* Ajuste de `n_estimators`, `max_depth`, `learning_rate`, `subsample`
* Resultado:

  * ROC-AUC: **0.9129**
  * Precision: **0.7604**
  * Recall: **0.7449**

â†’ Performance reduziu por conta da amostra reduzida (esperado).

---

### **4. XGBoost (Tuned)**

* Ajuste de `eta`, `subsample`, `colsample_bytree`, `max_depth`
* (Inclui early stopping automÃ¡tico)

Resultado:

* ROC-AUC: **0.9758** *(melhor do tuning)*
* Precision: **0.8947**
* Recall: **0.6939**

â†’ Melhor modelo em AUC + precisÃ£o.

---

### **5. LightGBM (Tuned)**

* Ajuste de `learning_rate`, `n_estimators`, profundidade, leaves
* Resultado:

  * ROC-AUC: **0.5480**

â†’ NÃ£o performou bem com dataset reduzido (comportamento esperado).

---

# ğŸ† ComparaÃ§Ã£o â€” Modelos Tunados

| Modelo                      | ROC-AUC | Recall | Precision |
| --------------------------- | ------- | ------ | --------- |
| Logistic Regression (Tuned) | 0.9755  | 0.5714 | 0.8235    |
| Random Forest (Tuned)       | 0.9652  | 0.7959 | 0.8764    |
| Gradient Boosting (Tuned)   | 0.9129  | 0.7449 | 0.7604    |
| XGBoost (Tuned)             | 0.9758  | 0.6939 | 0.8947    |
| LightGBM (Tuned)            | 0.5480  | 0.1735 | 0.0829    |

## âœ” ConclusÃµes do Tuning (Dia 8)

* **Melhor modelo geral:** XGBoost (Tuned)
* **Melhor modelo equilibrado:** Random Forest (Tuned)
* **Mais conservador (alta precisÃ£o):** Logistic Regression (Tuned)
* **Modelo que falhou com amostra reduzida:** LightGBM (Tuned)

---

# ğŸ“„ RelatÃ³rio PDF AutomÃ¡tico â€” (NOVO)

Agora o projeto gera automaticamente:

âœ” Tabela completa de mÃ©tricas
âœ” GrÃ¡ficos dos modelos
âœ” ConclusÃ£o automÃ¡tica (melhor AUC, recall, precisÃ£o)
âœ” PDF final em:

```
reports/model_report.pdf
```

Implementado em **`src/reporting.py`**.

---

# ğŸ”® PrÃ³ximas Etapas

### ğŸ’¡ Machine Learning AvanÃ§ado

* Threshold tuning
* Grid Search / Optuna
* Ensemble (Stacking)

### ğŸ§  Deep Learning

* MLP
* BatchNorm + Dropout
* Early Stopping

### ğŸš€ Deploy

* Pipeline de produÃ§Ã£o
* API com FastAPI
* Endpoint `/predict`
* Versionamento de modelos

---

# âš™ Tecnologias Utilizadas

* Python 3.10+
* Pandas / NumPy
* Matplotlib / Seaborn
* Scikit-learn
* Imbalanced-Learn
* XGBoost
* LightGBM
* TensorFlow
* Joblib
* Openpyxl
* ReportLab

---

# ğŸ“Œ Status Atual

### âœ” ConcluÃ­do

* EDA
* Pipeline completo
* Balanceamento com SMOTE
* Treinamento de 5 modelos
* Tuning de 5 modelos
* RelatÃ³rio PDF final
* ComparaÃ§Ã£o automatizada

### â¡ PrÃ³xima etapa

* SeleÃ§Ã£o do modelo final
* API com FastAPI
* Threshold tuning

---
