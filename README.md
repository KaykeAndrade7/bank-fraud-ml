# ğŸ¦ Credit Fraud Detection â€” Machine Learning

### PrevisÃ£o de transaÃ§Ãµes bancÃ¡rias fraudulentas usando aprendizado de mÃ¡quina

Este projeto implementa um pipeline completo para **detecÃ§Ã£o de fraudes em cartÃµes de crÃ©dito**, utilizando o dataset real *Credit Card Fraud Detection* do Kaggle.
O foco Ã© construir um sistema escalÃ¡vel, interpretÃ¡vel e aplicÃ¡vel a cenÃ¡rios reais do setor bancÃ¡rio.

---

## ğŸ“Š Dataset

**Fonte:** Kaggle â€” *Credit Card Fraud Detection*
**Link:** [https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)

### **CaracterÃ­sticas principais:**

* 284.807 transaÃ§Ãµes
* Apenas **0,17%** sÃ£o fraudulentas â†’ *problema severamente desbalanceado*
* Features V1â€“V28 geradas por PCA (dados anonimizados)
* Coluna **Class** Ã© a variÃ¡vel-alvo:

  * `0` â†’ transaÃ§Ã£o normal
  * `1` â†’ transaÃ§Ã£o fraudulenta

---

## ğŸ” Exploratory Data Analysis (EDA)

### âœ” DistribuiÃ§Ã£o das classes

* Fraudes representam menos de 1%.
* Indica necessidade de tÃ©cnicas de balanceamento (SMOTE).

### âœ” AnÃ¡lise das Features

* VariÃ¡veis PCA apresentam padrÃµes distintos entre fraudes e nÃ£o fraudes.
* `Amount` apresenta cauda longa e variÃ¢ncia elevada.

### âœ” CorrelaÃ§Ã£o

* Componentes **V17, V14 e V12** tÃªm forte correlaÃ§Ã£o com a classe.
* PCA preserva sinais importantes para classificaÃ§Ã£o.

### âœ” Outliers

* Mantidos, pois sÃ£o esperados apÃ³s transformaÃ§Ã£o PCA.

### âœ” GrÃ¡ficos utilizados

* Histogramas por classe
* Countplot da variÃ¡vel alvo
* Heatmap de correlaÃ§Ã£o
* Boxplots exploratÃ³rios

---

## ğŸ§¹ PrÃ©-processamento

Implementado em **`src/preprocessing.py`** como um pipeline automatizado e modular.

### âœ” 1. SeparaÃ§Ã£o X / y

* `Class` = target
* Demais colunas = features

### âœ” 2. Train-Test Split (80/20)

* DivisÃ£o estratificada para manter a proporÃ§Ã£o real de fraudes.

### âœ” 3. NormalizaÃ§Ã£o (StandardScaler)

* Ajustado **somente no treino**
* Aplicado no teste para evitar *data leakage*
* Scaler salvo em:

```
models/scaler.pkl
```

### âœ” 4. Balanceamento com SMOTE

* Aplicado **apenas no treino**
* Cria exemplos sintÃ©ticos da classe minoritÃ¡ria

### âœ” 5. Salvamento dos dados processados

Arquivos gerados em:

```
data/processed/
  â”œâ”€â”€ X_train_bal.npy
  â”œâ”€â”€ X_test.npy
  â”œâ”€â”€ y_train_bal.npy
  â”œâ”€â”€ y_test.npy
```

### âœ” 6. Pipeline completo (`preprocess_pipeline()`)

Fluxo:

1. Carrega dados
2. Separa features e target
3. Divide treino/teste
4. Escala
5. Aplica SMOTE
6. Salva scaler + arrays
7. Retorna formatos finais

---

# ğŸ¤– Modelagem

ApÃ³s o prÃ©-processamento, foram treinados trÃªs modelos:

---

# **ğŸ“Œ 1. Logistic Regression**

### ğŸ“Š Resultados

**ROC-AUC:** 0.9709
**Recall:** 0.9183
**Precision:** 0.0579

### ğŸ§© Matriz de ConfusÃ£o

|            | Previsto 0 | Previsto 1 |
| ---------- | ---------- | ---------- |
| **Real 0** | 55402      | 1462       |
| **Real 1** | 8          | 90         |

### âœ” InterpretaÃ§Ã£o

* Excelente separaÃ§Ã£o geral (AUC 0.97)
* Ã“timo recall (captura a maioria das fraudes)
* Baixa precisÃ£o devido ao desbalanceamento
* Erra pouco em deixar fraudes passarem (somente 8)

---

# **ğŸ“Œ 2. Random Forest**

### ğŸ“Š Resultados

**ROC-AUC:** 0.9684
**Recall:** 0.8265
**Precision:** 0.8709

### ğŸ§© Matriz de ConfusÃ£o

|            | Previsto 0 | Previsto 1 |
| ---------- | ---------- | ---------- |
| **Real 0** | 56852      | 12         |
| **Real 1** | 17         | 81         |

### âœ” InterpretaÃ§Ã£o

* AltÃ­ssima precisÃ£o (87%) â†’ excelente para evitar falsos alarmes
* Recall mais baixo que LR/GB (perde algumas fraudes)
* Ã“tima escolha quando se quer precisÃ£o de alertas

---

# **ğŸ“Œ 3. Gradient Boosting**

### ğŸ“Š Resultados

**ROC-AUC:** 0.9809
**Recall:** 0.9183
**Precision:** 0.1133

### ğŸ§© Matriz de ConfusÃ£o

|            | Previsto 0 | Previsto 1 |
| ---------- | ---------- | ---------- |
| **Real 0** | 56160      | 704        |
| **Real 1** | 8          | 90         |

### âœ” InterpretaÃ§Ã£o

* Melhor AUC entre os modelos
* Recall igual ao da RegressÃ£o LogÃ­stica
* PrecisÃ£o baixa, mas esperada para problemas severamente desbalanceados

---

# ğŸ† ComparaÃ§Ã£o Geral dos Modelos

| Modelo              | ROC-AUC | Recall | Precision |
| ------------------- | ------- | ------ | --------- |
| Logistic Regression | 0.9709  | 0.9183 | 0.0579    |
| Random Forest       | 0.9684  | 0.8265 | 0.8709    |
| Gradient Boosting   | 0.9809  | 0.9183 | 0.1133    |

### âœ” InterpretaÃ§Ã£o Profissional

* **Maior AUC:** Gradient Boosting
* **Maior Recall:** Logistic Regression / Gradient Boosting
* **Maior Precision:** Random Forest (de longe)

Cada modelo tem forÃ§a diferente â†’ ideal para ensemble no futuro.

---

## ğŸ”® PrÃ³ximas Etapas 

### ML AvanÃ§ado

* XGBoost
* LightGBM
* Ensemble (votaÃ§Ã£o ou stacking)

### Deep Learning

* MLP simples
* Batch Normalization
* Early Stopping

### Infraestrutura

* Scripts automatizados
* ComparaÃ§Ã£o final dos modelos
* SeleÃ§Ã£o de modelo para produÃ§Ã£o

---

## âš™ Tecnologias Utilizadas

* Python 3.10+
* Pandas / NumPy
* Matplotlib / Seaborn
* Scikit-learn
* Imbalanced-Learn (SMOTE)
* TensorFlow (CPU)
* Joblib
* Jupyter Notebook

---

## ğŸ“Œ Status Atual

### âœ” ConcluÃ­do atÃ© agora:

* EDA completo
* Pipeline de prÃ©-processamento
* Balanceamento com SMOTE
* Treinamento de:

  * Logistic Regression
  * Random Forest
  * Gradient Boosting

### â¡ PrÃ³xima etapa:

* Modelos avanÃ§ados e tuning

---
