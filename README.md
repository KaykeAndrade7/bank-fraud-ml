# ğŸ¦ Credit Fraud Detection â€” Machine Learning

### PrevisÃ£o de transaÃ§Ãµes bancÃ¡rias fraudulentas usando aprendizado de mÃ¡quina

Este projeto implementa um pipeline completo para **detecÃ§Ã£o de fraudes em cartÃµes de crÃ©dito**, utilizando o dataset real *Credit Card Fraud Detection* do Kaggle.
O objetivo Ã© construir um sistema escalÃ¡vel, interpretÃ¡vel e aplicÃ¡vel a cenÃ¡rios reais do setor bancÃ¡rio â€” passando por EDA, prÃ©-processamento, modelagem, tuning, relatÃ³rios automÃ¡ticos e agora **infraestrutura inicial de produÃ§Ã£o**.

---

# ğŸ“Š Dataset

**Fonte:** Kaggle â€” *Credit Card Fraud Detection*
Link: [https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)

### CaracterÃ­sticas

* 284.807 transaÃ§Ãµes
* Apenas **0,17%** sÃ£o fraudes
* Features **V1â€“V28** geradas via PCA
* `Class`:

  * `0` â†’ legÃ­tima
  * `1` â†’ fraudulenta

---

# ğŸ” Exploratory Data Analysis (EDA)

âœ” Fraudes < 1%
âœ” PCA destaca V17, V14 e V12
âœ” `Amount` muito assimÃ©trica
âœ” GrÃ¡ficos incluÃ­ram histogramas, boxplots, correlaÃ§Ã£o
âœ” Outliers mantidos

---

# ğŸ§¹ PrÃ©-processamento

Pipeline implementado em `src/preprocessing.py`:

1. SeparaÃ§Ã£o X/y
2. Train-test split estratificado
3. NormalizaÃ§Ã£o (StandardScaler)
4. Balanceamento SMOTE
5. Salvamento dos arrays prÃ©-processados

Arquivos gerados:

```
data/processed/
  â”œâ”€â”€ X_train_bal.npy
  â”œâ”€â”€ X_test.npy
  â”œâ”€â”€ y_train_bal.npy
  â”œâ”€â”€ y_test.npy
```

Scaler salvo em:

```
models/scaler.pkl
```

---

# ğŸ¤– Modelagem â€” Modelos Base

Modelos inicialmente treinados sem tuning:

* Logistic Regression
* Random Forest
* Gradient Boosting
* XGBoost
* LightGBM

---

# âš™ï¸ Dia 8 â€” Tuning de HiperparÃ¢metros (NOVO)

Cada modelo foi otimizado com RandomizedSearchCV.
Objetivos:

âœ” Reduzir custo computacional
âœ” Aumentar ROC-AUC
âœ” Melhorar recall e precisÃ£o sem overfit

FunÃ§Ãµes em: `src/tuning.py`

---

# ğŸ† Resultados â€” Modelos Tunados

| Modelo                      | ROC-AUC | Recall | Precision |
| --------------------------- | ------- | ------ | --------- |
| Logistic Regression (Tuned) | 0.9755  | 0.5714 | 0.8235    |
| Random Forest (Tuned)       | 0.9652  | 0.7959 | 0.8764    |
| Gradient Boosting (Tuned)   | 0.9129  | 0.7449 | 0.7604    |
| XGBoost (Tuned)             | 0.9758  | 0.6939 | 0.8947    |
| LightGBM (Tuned)            | 0.5480  | 0.1735 | 0.0829    |

### ConclusÃµes do Tuning

* **Melhor modelo geral:** XGBoost (Tuned)
* **Mais equilibrado:** Random Forest (Tuned)
* **Maior precisÃ£o:** XGBoost (Tuned)
* **Modelo com pior impacto de amostra reduzida:** LightGBM

---

# ğŸ“„ RelatÃ³rio PDF AutomÃ¡tico (NOVO)

Gerado automaticamente pelo cÃ³digo:

```
reports/model_report.pdf
```

Inclui:

âœ” Tabela de mÃ©tricas
âœ” GrÃ¡ficos de ROC-AUC, Recall e Precision
âœ” ConclusÃµes automÃ¡ticas
âœ” Melhor modelo destacado

ImplementaÃ§Ã£o em: `src/reporting.py`.

---

# ğŸ§  Dia 9 â€” PreparaÃ§Ã£o para ProduÃ§Ã£o (NOVO)

Nesta etapa o projeto deixa de ser apenas um pipeline offline e passa a ter **estrutura de produÃ§Ã£o real**.

## âœ” SeleÃ§Ã£o automÃ¡tica do modelo final

Criado em `src/modeling.py`:

* Combina AUC, Recall e Precision em um **score composto**
* Retorna automaticamente:

  * nome do melhor modelo
  * caminho do arquivo .pkl
  * score final

O modelo selecionado Ã© salvo como:

```
models/modelo_final.pkl
```

---

# ğŸ§ª FunÃ§Ãµes de InferÃªncia (NOVO)

Criado o mÃ³dulo:

```
src/inference.py
```

ContÃ©m:

### âœ” `predict_single_transaction()`

Recebe um dicionÃ¡rio â†’ retorna:

* probabilidade de fraude
* classe prevista

### âœ” `predict_batch()`

Recebe um DataFrame â†’ retorna lista de previsÃµes.

### âœ” `predict_pipeline()`

Pipeline real usado em produÃ§Ã£o:

* carrega scaler e modelo
* ordena features
* aplica normalizaÃ§Ã£o
* roda prediÃ§Ã£o
* retorna saÃ­da padronizada

---

# ğŸš€ API com FastAPI (NOVO â€” Dia 9)

Criada a estrutura inicial em:

```
api/app.py
```

### Endpoints disponÃ­veis:

#### âœ” `GET /`

Teste simples da API.

#### âœ” `POST /predict`

Recebe uma transaÃ§Ã£o
Retorna:

```json
{
  "fraud_probability": 0.87,
  "prediction": 1
}
```

#### âœ” `POST /predict-batch`

Recebe lista de transaÃ§Ãµes
Retorna previsÃµes em lote.

### Carregamento automÃ¡tico

Ao iniciar a API:

âœ” modelo_final.pkl
âœ” scaler.pkl
âœ” feature_order.json

sÃ£o carregados automaticamente.

---

# ğŸ§© Estrutura Atualizada do Projeto

```
/api
   â”œâ”€â”€ app.py
   â”œâ”€â”€ client.py
/src
   â”œâ”€â”€ preprocessing.py
   â”œâ”€â”€ modeling.py
   â”œâ”€â”€ tuning.py
   â”œâ”€â”€ inference.py
   â”œâ”€â”€ reporting.py
/models
   â”œâ”€â”€ modelo_final.pkl
   â”œâ”€â”€ scaler.pkl
   â”œâ”€â”€ feature_order.json
/reports
   â”œâ”€â”€ model_report.pdf
```

---

# ğŸ“Œ Status Atual (Atualizado atÃ© Dia 9)

### âœ” ConcluÃ­do

âœ“ EDA completo
âœ“ PrÃ©-processamento + SMOTE
âœ“ Treinamento de 5 modelos
âœ“ Tuning de 5 modelos
âœ“ AvaliaÃ§Ã£o comparativa
âœ“ GrÃ¡ficos automatizados
âœ“ RelatÃ³rio PDF
âœ“ SeleÃ§Ã£o automÃ¡tica do melhor modelo
âœ“ CriaÃ§Ã£o completa da API (predict e batch)
âœ“ Pipeline real de inferÃªncia
âœ“ Modelo final salvo

---

# ğŸ”® PrÃ³ximas Etapas 

* Ajuste fino do threshold
* Stacking/Ensemble avanÃ§ado
* PersistÃªncia de logs
* Deploy na nuvem (Railway / Render / AWS)
* Monitoramento de drift
* Interface web simples (Streamlit)
* DockerizaÃ§Ã£o

---

