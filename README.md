# ğŸ¦ Credit Fraud Detection â€” Machine Learning

### PrevisÃ£o de transaÃ§Ãµes bancÃ¡rias fraudulentas usando aprendizado de mÃ¡quina

Este projeto implementa um pipeline completo para **detecÃ§Ã£o de fraudes em cartÃµes de crÃ©dito**, utilizando o dataset real *Credit Card Fraud Detection* do Kaggle.
O objetivo Ã© construir um sistema escalÃ¡vel, interpretÃ¡vel e aplicÃ¡vel a cenÃ¡rios reais do setor bancÃ¡rio.

---

## ğŸ“Š Dataset

**Fonte:** Kaggle â€” *Credit Card Fraud Detection*
**Link:** [https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)

### **CaracterÃ­sticas principais**

* 284.807 transaÃ§Ãµes
* Apenas **0,17%** sÃ£o fraudes (*dataset extremamente desbalanceado*)
* Features **V1â€“V28** foram obtidas via PCA (dados anonimizados)
* Coluna **Class** Ã© o alvo:

  * `0` â†’ transaÃ§Ã£o legÃ­tima
  * `1` â†’ transaÃ§Ã£o fraudulenta

---

## ğŸ” Exploratory Data Analysis (EDA)

### âœ” DistribuiÃ§Ã£o das classes

Fraudes representam menos de 1%, exigindo tÃ©cnicas de balanceamento como SMOTE.

### âœ” AnÃ¡lise das Features

* Componentes PCA apresentam padrÃµes diferentes entre fraude e nÃ£o fraude.
* `Amount` possui alta variabilidade e cauda longa.

### âœ” CorrelaÃ§Ã£o

* **V17, V14 e V12** tÃªm maior peso na detecÃ§Ã£o de fraude.

### âœ” Outliers

* Mantidos â€” sÃ£o esperados apÃ³s transformaÃ§Ã£o PCA.

### âœ” GrÃ¡ficos utilizados

* Histogramas
* Countplot da variÃ¡vel alvo
* Heatmap de correlaÃ§Ã£o
* Boxplots

---

## ğŸ§¹ PrÃ©-processamento

Pipeline implementado em **`src/preprocessing.py`**.

### âœ” Etapas

1. SeparaÃ§Ã£o X / y
2. Train-test split estratificado (80/20)
3. NormalizaÃ§Ã£o com **StandardScaler**
4. Balanceamento com **SMOTE**
5. Salvamento dos arrays processados

Arquivos gerados:

```
data/processed/
  â”œâ”€â”€ X_train_bal.npy
  â”œâ”€â”€ X_test.npy
  â”œâ”€â”€ y_train_bal.npy
  â”œâ”€â”€ y_test.npy
```

Scaler salvo em:

```
models/scaler.pkl
```

Fluxo completo: carregar â†’ separar â†’ dividir â†’ escalar â†’ balancear â†’ salvar.

---

# ğŸ¤– Modelagem

Foram treinados **5 modelos**:

* Logistic Regression
* Random Forest
* Gradient Boosting
* XGBoost
* LightGBM

Treinamento realizado em **`train_model.py`**.

---

# ğŸ“Œ 1. Logistic Regression

### ğŸ“Š Resultados

* **ROC-AUC:** 0.9709
* **Recall:** 0.9183
* **Precision:** 0.0579

### ğŸ§© Matriz de ConfusÃ£o

| Real \ Previsto | 0     | 1    |
| --------------- | ----- | ---- |
| **0**           | 55402 | 1462 |
| **1**           | 8     | 90   |

### âœ” InterpretaÃ§Ã£o

Alta separaÃ§Ã£o e excelente recall; precisÃ£o baixa Ã© esperada em cenÃ¡rios desbalanceados.

---

# ğŸ“Œ 2. Random Forest

### ğŸ“Š Resultados

* **ROC-AUC:** 0.9684
* **Recall:** 0.8265
* **Precision:** 0.8709

### ğŸ§© Matriz de ConfusÃ£o

| Real \ Previsto | 0     | 1  |
| --------------- | ----- | -- |
| **0**           | 56852 | 12 |
| **1**           | 17    | 81 |

### âœ” InterpretaÃ§Ã£o

Modelo muito preciso, ideal quando se deseja evitar falsos positivos, mas perde algumas fraudes.

---

# ğŸ“Œ 3. Gradient Boosting

### ğŸ“Š Resultados

* **ROC-AUC:** 0.9809
* **Recall:** 0.9183
* **Precision:** 0.1133

### ğŸ§© Matriz de ConfusÃ£o

| Real \ Previsto | 0     | 1   |
| --------------- | ----- | --- |
| **0**           | 56160 | 704 |
| **1**           | 8     | 90  |

### âœ” InterpretaÃ§Ã£o

Melhor AUC entre todos os modelos; recall muito alto.

---

# ğŸ“Œ 4. XGBoost

### ğŸ“Š Resultados

* **ROC-AUC:** 0.9800
* **Recall:** 0.8775
* **Precision:** 0.2409

### ğŸ§© Matriz de ConfusÃ£o

| Real \ Previsto | 0     | 1   |
| --------------- | ----- | --- |
| **0**           | 56593 | 271 |
| **1**           | 12    | 86  |

### âœ” InterpretaÃ§Ã£o

Ã“timo equilÃ­brio entre recall e precisÃ£o.

---

# ğŸ“Œ 5. LightGBM

### ğŸ“Š Resultados

* **ROC-AUC:** 0.9568
* **Recall:** 0.8367
* **Precision:** 0.6259

### ğŸ§© Matriz de ConfusÃ£o

| Real \ Previsto | 0     | 1  |
| --------------- | ----- | -- |
| **0**           | 56815 | 49 |
| **1**           | 16    | 82 |

### âœ” InterpretaÃ§Ã£o

Boa precisÃ£o; menor AUC comparado aos demais.

---

# ğŸ† ComparaÃ§Ã£o Geral

| Modelo              | ROC-AUC | Recall | Precision |
| ------------------- | ------- | ------ | --------- |
| Logistic Regression | 0.9709  | 0.9183 | 0.0579    |
| Random Forest       | 0.9684  | 0.8265 | 0.8709    |
| Gradient Boosting   | 0.9809  | 0.9183 | 0.1133    |
| XGBoost             | 0.9800  | 0.8775 | 0.2409    |
| LightGBM            | 0.9568  | 0.8367 | 0.6259    |

### âœ” ConclusÃµes Profissionais

* **Melhor AUC:** Gradient Boosting
* **Melhor Recall:** Logistic Regression & Gradient Boosting
* **Melhor Precision:** Random Forest

Cada modelo mostra forÃ§as diferentes â€” excelente caso para ensemble.

---

# ğŸ”® PrÃ³ximas Etapas

### ğŸ”§ Machine Learning AvanÃ§ado

* HiperparametrizaÃ§Ã£o (Grid Search / Optuna)
* Ensemble (VotaÃ§Ã£o, Stacking)

### ğŸ¤– Deep Learning

* MLP
* Dropout / BatchNorm
* Early Stopping

### ğŸ— Infraestrutura

* Pipeline de produÃ§Ã£o
* API com FastAPI
* Script de inferÃªncia

---

## âš™ Tecnologias Utilizadas

* Python 3.10+
* Pandas / NumPy
* Matplotlib / Seaborn
* Scikit-learn
* Imbalanced-Learn
* XGBoost / LightGBM
* TensorFlow
* Joblib
* Jupyter Notebook
* ReportLab
* Openpyxl

---

## ğŸ“Œ Status Atual

### âœ” ConcluÃ­do

* EDA completo
* Pipeline de prÃ©-processamento
* SMOTE
* Treinamento e comparaÃ§Ã£o de **5 modelos**
* GeraÃ§Ã£o de mÃ©tricas e grÃ¡ficos

### â¡ PrÃ³xima Etapa

* Tuning
* API
* Modelo final para produÃ§Ã£o

---